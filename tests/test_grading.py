import os
import logging
import numpy as np
import src.grading as grading
import usgs_grading_metric as usgs_grading
import cmaas_utils.io as io
from tests.utilities import init_test_log

legends_dir = 'tests/data/legends'
maps_dir = 'tests/data/map_images'
pred_segs_dir = 'tests/data/pred_segmentations'
true_segs_dir = 'tests/data/true_segmentations'

class Test_grade_poly_raster:
    def run_test_grade_poly_raster(self, map_name, feature_name, log, map_dir=maps_dir, legend_dir=legends_dir, pred_seg_dir=pred_segs_dir, true_seg_dir=true_segs_dir):
        """
        Runs grade_poly_raster for an arbitrary map and feature.
        Tests that the F1 Score, Precision, and Recall scores generated by grade_poly_raster are the same as the USGS grading metric.
        This function is not a test itself.
        """
        map_image_filepath = os.path.join(map_dir, f'{map_name}.tif')
        legend_filepath = os.path.join(legend_dir, f'{map_name}.json')
        pred_seg_filepath = os.path.join(pred_seg_dir, f'{map_name}_{feature_name}.tif')
        true_seg_filepath = os.path.join(true_seg_dir, f'{map_name}_{feature_name}.tif')

        # Test our grading function
        pred_seg = np.squeeze(io.loadGeoTiff(pred_seg_filepath)[0])
        true_seg = np.squeeze(io.loadGeoTiff(true_seg_filepath)[0])
        test_result, _ = grading.grade_poly_raster(pred_seg, true_seg)

        # Get expected results from usgs grading
        usgs_result = usgs_grading.feature_f_score(map_image_filepath, pred_seg_filepath, true_seg_filepath, legend_json_path=legend_filepath, difficult_weight=None)

        log.info(f'{map_name}_{feature_name} | ' +
                    f'F1 Score : {test_result["F1 Score"]} == {usgs_result["f_score"]}, ' +
                    f'Precision : {test_result["Precision"]} == {usgs_result["precision"]}, ' +
                    f'Recall : {test_result["Recall"]} == {usgs_result["recall"]}')
        assert test_result['F1 Score'] == usgs_result['f_score']
        assert test_result['Precision'] == usgs_result['precision']
        assert test_result['Recall'] == usgs_result['recall']

    def test_mock_map(self):
        """
        Tests that the F1 Score, Precision, and Recall scores generated by grade_poly_raster are the same as the USGS grading metric.
        Data used for this test is a mock map that is 100x100 pixels. The mock map has two poly features, L_poly and TZ_poly.
        """
        log = init_test_log('Test_grade_poly_raster/test_mock_map')

        mock_poly_units = ['L_poly', 'TZ_poly']
        for poly_unit in mock_poly_units:
            self.run_test_grade_poly_raster('mock_map', poly_unit, log)
        log.info('Test passed successfully')

    # def test_MT_Havre_map(self):
    #     """
    #     Tests that the F1 Score, Precision, and Recall scores generated by grade_poly_raster are the same as the USGS grading metric.
    #     Data used for this test is the poly features from MT_Havre, which is from the final evaluation dataset.
    #     This test is commented out beacuse the test data is too large to be commited to the repository.
    #     """
    #     log = init_test_log('Test_grade_poly_raster/test_MT_Havre_map')
    #     map_dir = 'tests/uncommited_data/map_images'
    #     legend_dir = 'tests/uncommited_data/legends'
    #     pred_seg_dir = 'tests/uncommited_data/pred_segmentations'
    #     true_seg_dir = 'tests/uncommited_data/true_segmentations'

    #     # full_poly_units = ['afj_poly', 'al_poly', 'alt_poly', 'aqa_poly', 'asr_poly', 'caa_poly','cad_poly','cax_poly','cly_poly','crg_poly','gg_poly','IT_poly','jea_poly','ke_poly','kg_poly','lca_poly','lse_poly','lu_poly','lx_poly','pgd_poly','R_poly','tks_e_poly','tks_poly','tlx_e_poly','tlx_poly','tlx_s_poly']
    #     sample_poly_units = ['cly_poly', 'kg_poly', 'alt_poly', 'tlx_poly', 'R_poly']
    #     for poly_unit in sample_poly_units:
    #         self.run_test_grade_poly_raster('MT_Havre', poly_unit, log, map_dir=map_dir, legend_dir=legend_dir, pred_seg_dir=pred_seg_dir, true_seg_dir=true_seg_dir)
    #     log.info('Test passed successfully')

    # def test_CA_Elisnore_map(self):
    #     """
    #     Tests that the F1 Score, Precision, and Recall scores generated by grade_poly_raster are the same as the USGS grading metric.
    #     Data used for this test is the poly features from CA_Elsinore, which is from the validation dataset.
    #     This test is commented out beacuse the test data is too large to be commited to the repository.
    #     """
    #     log = init_test_log('Test_grade_poly_raster/test_CA_Elisnore_map')
    #     map_dir = 'tests/uncommited_data/map_images'
    #     legend_dir = 'tests/uncommited_data/legends'
    #     pred_seg_dir = 'tests/uncommited_data/pred_segmentations'
    #     true_seg_dir = 'tests/uncommited_data/true_segmentations'

    #     # full_poly_units = ['Katg_poly','Kgb_poly','Kgbf_poly','Kgd_poly','Kgh_poly','Kgt_poly','Khg_poly','Kpvg_poly','Ksv_poly','Kvem_poly','Kvs_poly','Kvsp_poly','Mzm_poly','Mzp_poly','Mzq_poly','Mzu_poly','Qaf_poly','Qf_poly','Ql_poly','Qoa_poly','Qpf_poly','Qpfs_poly','Qvoa_poly','Qvof_poly','Qw_poly','Qya_poly','Qyf_poly','Tcg_poly','Tsi_poly']
    #     sample_poly_units = ['Qyf_poly', 'Kgbf_poly', 'Qpf_poly', 'Tcg_poly', 'Kvsp_poly']
    #     for poly_unit in sample_poly_units:
    #         self.run_test_grade_poly_raster('CA_Elsinore', poly_unit, log, map_dir=map_dir, legend_dir=legend_dir, pred_seg_dir=pred_seg_dir, true_seg_dir=true_seg_dir)
    #     log.info('Test passed successfully')

class Test_usgs_grade_poly_raster:
    def run_test_usgs_grade_poly_raster(self, map_name, feature_name, log, map_dir=maps_dir, legend_dir=legends_dir, pred_seg_dir=pred_segs_dir, true_seg_dir=true_segs_dir):
        """
        Runs usgs_grade_poly_raster for an arbitrary map and feature.
        Tests that the F1 Score, Precision, and Recall scores generated by usgs_grade_poly_raster are the same as the USGS grading metric.
        This function is not a test itself.
        """
        map_image_filepath = os.path.join(map_dir, f'{map_name}.tif')
        legend_filepath = os.path.join(legend_dir, f'{map_name}.json')
        pred_seg_filepath = os.path.join(pred_seg_dir, f'{map_name}_{feature_name}.tif')
        true_seg_filepath = os.path.join(true_seg_dir, f'{map_name}_{feature_name}.tif')

        # Test our grading function
        map_image = io.loadGeoTiff(map_image_filepath)[0]
        legend = io.loadLegendJson(legend_filepath)
        pred_seg = io.loadGeoTiff(pred_seg_filepath)[0]
        true_seg = io.loadGeoTiff(true_seg_filepath)[0]
        feature = [f for f in legend.features if f.label == feature_name.split('_')[0]][0]
        test_result, _ = grading.usgs_grade_poly_raster(pred_seg, true_seg, map_image, feature.bounding_box)

        # Get expected results from usgs grading
        usgs_result = usgs_grading.feature_f_score(map_image_filepath, pred_seg_filepath, true_seg_filepath, legend_json_path=legend_filepath)

        log.info(f'{map_name}_{feature_name} | ' +
                    f'F1 Score : {test_result["F1 Score"]} == {usgs_result["f_score"]}, ' +
                    f'Precision : {test_result["Precision"]} == {usgs_result["precision"]}, ' +
                    f'Recall : {test_result["Recall"]} == {usgs_result["recall"]}')
        assert test_result['F1 Score'] == usgs_result['f_score']
        assert test_result['Precision'] == usgs_result['precision']
        assert test_result['Recall'] == usgs_result['recall']

    def test_mock_map(self):
        """
        Tests that the F1 Score, Precision, and Recall scores generated by usgs_grade_poly_raster are the same as the USGS grading metric.
        Data used for this test is a mock map that is 100x100 pixels. The mock map has two poly features, L_poly and TZ_poly.
        """
        log = init_test_log('Test_usgs_grade_poly_raster/test_mock_map')

        mock_poly_units = ['L_poly', 'TZ_poly']
        for poly_unit in mock_poly_units:
            self.run_test_usgs_grade_poly_raster('mock_map', poly_unit, log)
        log.info('Test passed successfully')

    # def test_MT_Havre_map(self):
    #     """
    #     Tests that the F1 Score, Precision, and Recall scores generated by usgs_grade_poly_raster are the same as the USGS grading metric.
    #     Data used for this test is the poly features from MT_Havre, which is from the final evaluation dataset.
    #     This test is commented out beacuse the test data is too large to be commited to the repository.
    #     """
    #     log = init_test_log('Test_usgs_grade_poly_raster/test_MT_Havre_map')
    #     map_dir = 'tests/uncommited_data/map_images'
    #     legend_dir = 'tests/uncommited_data/legends'
    #     pred_seg_dir = 'tests/uncommited_data/pred_segmentations'
    #     true_seg_dir = 'tests/uncommited_data/true_segmentations'

    #     # full_poly_units = ['afj_poly', 'al_poly', 'alt_poly', 'aqa_poly', 'asr_poly', 'caa_poly','cad_poly','cax_poly','cly_poly','crg_poly','gg_poly','IT_poly','jea_poly','ke_poly','kg_poly','lca_poly','lse_poly','lu_poly','lx_poly','pgd_poly','R_poly','tks_e_poly','tks_poly','tlx_e_poly','tlx_poly','tlx_s_poly']
    #     sample_poly_units = ['cly_poly', 'kg_poly', 'alt_poly', 'tlx_poly', 'R_poly']
    #     for poly_unit in sample_poly_units:
    #         self.run_test_usgs_grade_poly_raster('MT_Havre', poly_unit, log, map_dir=map_dir, legend_dir=legend_dir, pred_seg_dir=pred_seg_dir, true_seg_dir=true_seg_dir)
    #     log.info('Test passed successfully')

    # def test_CA_Elisnore_map(self):
    #     """
    #     Tests that the F1 Score, Precision, and Recall scores generated by usgs_grade_poly_raster are the same as the USGS grading metric.
    #     Data used for this test is the poly features from CA_Elsinore, which is from the validation dataset.
    #     This test is commented out beacuse the test data is too large to be commited to the repository.
    #     """
    #     log = init_test_log('Test_usgs_grade_poly_raster/test_CA_Elisnore_map')
    #     map_dir = 'tests/uncommited_data/map_images'
    #     legend_dir = 'tests/uncommited_data/legends'
    #     pred_seg_dir = 'tests/uncommited_data/pred_segmentations'
    #     true_seg_dir = 'tests/uncommited_data/true_segmentations'

    #     # full_poly_units = ['Katg_poly','Kgb_poly','Kgbf_poly','Kgd_poly','Kgh_poly','Kgt_poly','Khg_poly','Kpvg_poly','Ksv_poly','Kvem_poly','Kvs_poly','Kvsp_poly','Mzm_poly','Mzp_poly','Mzq_poly','Mzu_poly','Qaf_poly','Qf_poly','Ql_poly','Qoa_poly','Qpf_poly','Qpfs_poly','Qvoa_poly','Qvof_poly','Qw_poly','Qya_poly','Qyf_poly','Tcg_poly','Tsi_poly']
    #     sample_poly_units = ['Qyf_poly', 'Kgbf_poly', 'Qpf_poly', 'Tcg_poly', 'Kvsp_poly']
    #     for poly_unit in sample_poly_units:
    #         self.run_test_usgs_grade_poly_raster('CA_Elsinore', poly_unit, log, map_dir=map_dir, legend_dir=legend_dir, pred_seg_dir=pred_seg_dir, true_seg_dir=true_seg_dir)
    #     log.info('Test passed successfully')


def debug_grade_point_raster(pred_image, true_image, feedback_image=None, min_valid_range=0.1):
    import math
    matched_pt_pairs = grading.match_nearest_points(true_image, pred_image, min_valid_range=min_valid_range)
    # Check if there were any matched points
    if (len(matched_pt_pairs) == 0):
        result = {
            'F1 Score' : 0, 
            'Precision' : 0, 
            'Recall' : 0,
            'Mean Matched Distance' : np.nan, 
            'Matched Points' : 0,
            'Missing Points' : np.count_nonzero(true_image), 
            'Unmatched Points' : np.count_nonzero(pred_image)
        }
        return result, feedback_image

    result = {}

    # Get the mean distance
    norm_mean_dist = sum([p[1] for p in matched_pt_pairs]) / len(matched_pt_pairs)
    map_size = math.sqrt(math.pow(true_image.shape[0], 2) + math.pow(true_image.shape[1], 2))
    result['Mean Matched Distance'] = norm_mean_dist * map_size
    result['Matched Points'] = len(matched_pt_pairs) # Green
    result['Missing Points'] = np.count_nonzero(true_image) - result['Matched Points'] # Pink
    result['Unmatched Points'] = np.count_nonzero(pred_image) - result['Matched Points'] # Red

    # Calculate statistical values
    sum_of_similarities = sum([1-item[1] for item in matched_pt_pairs])
    result['Precision'] = sum_of_similarities / np.count_nonzero(pred_image)
    result['Recall'] = sum_of_similarities / np.count_nonzero(true_image)
    result['F1 Score'] = (2 * result['Precision'] * result['Recall']) / (result['Precision'] + result['Recall'])

    return result, feedback_image

class Test_grade_point_raster:
    def run_test_grade_point_raster(self, map_name, feature_name, log, min_valid_range=0.1, map_dir=maps_dir, legend_dir=legends_dir, pred_seg_dir=pred_segs_dir, true_seg_dir=true_segs_dir):
        """ 
        Runs grade_point_raster for an arbitrary map and feature.
        Tests that the F1 Score, Precision, and Recall scores generated by grade_point_raster are the same as the USGS grading metric.
        This function is not a test itself.
        """
        map_image_filepath = os.path.join(map_dir, f'{map_name}.tif')
        legend_filepath = os.path.join(legend_dir, f'{map_name}.json')
        pred_seg_filepath = os.path.join(pred_seg_dir, f'{map_name}_{feature_name}.tif')
        true_seg_filepath = os.path.join(true_seg_dir, f'{map_name}_{feature_name}.tif')

        # Test our grading function
        pred_seg = np.squeeze(io.loadGeoTiff(pred_seg_filepath)[0])
        true_seg = np.squeeze(io.loadGeoTiff(true_seg_filepath)[0])
        
        test_result, _ = grading.grade_point_raster(pred_seg, true_seg, min_valid_range=min_valid_range)

        # Get expected results from usgs grading
        usgs_result = usgs_grading.feature_f_score(map_image_filepath, pred_seg_filepath, true_seg_filepath, legend_json_path=legend_filepath, min_valid_range=min_valid_range)

        log.info(f'{map_name}_{feature_name} | ' +
                    f'F1 Score : {test_result["F1 Score"]} == {usgs_result["f_score"]}, ' +
                    f'Precision : {test_result["Precision"]} == {usgs_result["precision"]}, ' +
                    f'Recall : {test_result["Recall"]} == {usgs_result["recall"]}')
        assert test_result['F1 Score'] == usgs_result['f_score']
        assert test_result['Precision'] == usgs_result['precision']
        assert test_result['Recall'] == usgs_result['recall']

    def test_mock_map(self):
        """
        Tests that the F1 Score, Precision, and Recall scores generated by grade_point_raster are the same as the USGS grading metric.
        Data used for this test is a mock map that is 100x100 pixels. The mock map has two point features, 2_pt and 3_pt.
        """
        log = init_test_log('Test_grade_point_raster/test_mock_map')
        min_valid_range = 10 # USGS uses 0.1 but the mock map size is to small for that to work.

        mock_point_units = ['2_pt', '3_pt']
        for point_unit in mock_point_units:
            self.run_test_grade_point_raster('mock_map', point_unit, log, min_valid_range=min_valid_range)
        log.info('Test passed successfully')

    # def test_MT_OldBaldy_map(self):
    #     """
    #     Tests that the F1 Score, Precision, and Recall scores generated by grade_point_raster are the same as the USGS grading metric.
    #     Data used for this test is the point features from MT_OldBaldyMountain_265833_1989_24000_geo_mosaic, which is from the final evaluation dataset.
    #     This test is commented out beacuse the test data is too large to be commited to the repository.
    #     """
    #     log = init_test_log('Test_grade_point_raster/test_MT_OldBaldy_map')
    #     map_dir = 'tests/uncommited_data/map_images'
    #     legend_dir = 'tests/uncommited_data/legends'
    #     pred_seg_dir = 'tests/uncommited_data/pred_segmentations'
    #     true_seg_dir = 'tests/uncommited_data/true_segmentations'

    #     point_units = ['1_pt', '2_pt', '3_pt', '4_pt', '5_pt']
    #     for point_unit in point_units:
    #         self.run_test_grade_point_raster('MT_OldBaldyMountain_265833_1989_24000_geo_mosaic', point_unit, log, map_dir=map_dir, legend_dir=legend_dir, pred_seg_dir=pred_seg_dir, true_seg_dir=true_seg_dir)
    #     log.info('Test passed successfully')

    # def test_CA_Elsinore_map(self):
    #     """
    #     Tests that the F1 Score, Precision, and Recall scores generated by grade_point_raster are the same as the USGS grading metric.
    #     Data used for this test is the point features from CA_Elsinore, which is from the validation dataset.
    #     This test is commented out beacuse the test data is too large to be commited to the repository.
    #     """
    #     log = init_test_log('Test_grade_point_raster/test_CA_Elsinore_map')
    #     map_dir = 'tests/uncommited_data/map_images'
    #     legend_dir = 'tests/uncommited_data/legends'
    #     pred_seg_dir = 'tests/uncommited_data/pred_segmentations'
    #     true_seg_dir = 'tests/uncommited_data/true_segmentations'
        
    #     point_units = ['igneous_foliation_pt','incl_meta_foliation_pt','inclined_bedding_pt','vert_meta_foliation_pt']
    #     for point_unit in point_units:
    #         self.run_test_grade_point_raster('CA_Elsinore', point_unit, log, map_dir=map_dir, legend_dir=legend_dir, pred_seg_dir=pred_seg_dir, true_seg_dir=true_seg_dir)
    #     log.info('Test passed successfully')

# region internal functions
class Test_match_nearest_points:
    def run_test_match_nearest_points(self, map_name, feature_name, log, min_valid_range=0.1, pred_seg_dir=pred_segs_dir, true_seg_dir=true_segs_dir):
        """
        Runs match_nearest_points for an arbitrary map and feature.
        Tests that the results generated by match_nearest_points are the same as the USGS grading metric.
        match_nearest_points is used by grade_point_raster to generate find the distance between nearest points in the predicted and true segmentations.
        This function is not a test itself.
        """
        pred_seg_filepath = os.path.join(pred_seg_dir, f'{map_name}_{feature_name}.tif')
        true_seg_filepath = os.path.join(true_seg_dir, f'{map_name}_{feature_name}.tif')

        # Test our function
        pred_seg_img = np.squeeze(io.loadGeoTiff(pred_seg_filepath)[0])
        true_seg_img = np.squeeze(io.loadGeoTiff(true_seg_filepath)[0])
        
        log.debug(f'pred_seg points : {np.count_nonzero(pred_seg_img)}')
        log.debug(f'true_seg points : {np.count_nonzero(true_seg_img)}')
        test_result = grading.match_nearest_points(true_seg_img, pred_seg_img, min_valid_range=min_valid_range)

        # Get expected results from usgs grading
        usgs_result = usgs_grading.overlap_distance_calculate(true_seg_img, pred_seg_img, min_valid_range=min_valid_range)

        log.info(f'{map_name}_{feature_name} results : {test_result} == {usgs_result}')
        assert test_result == usgs_result

    def test_mock_map(self):
        """
        Tests that the results generated by match_nearest_points are the same as the USGS grading metric.
        Data used for this test is a mock map that is 100x100 pixels. The mock map has two point features, 2_pt and 3_pt.
        """
        log = init_test_log('Test_match_nearest_points/test_mock_map')
        min_valid_range = 10 # USGS uses 0.1 but the mock map size is to small for that to work.

        mock_point_units = ['2_pt', '3_pt']
        for point_unit in mock_point_units:
            self.run_test_match_nearest_points('mock_map', point_unit, log, min_valid_range=min_valid_range)
        log.info('Test passed successfully')

    # def test_MT_OldBaldy_map(self):
    #     """
    #     Tests that the results generated by match_nearest_points are the same as the USGS grading metric.
    #     Data used for this test is the point features from MT_OldBaldyMountain_265833_1989_24000_geo_mosaic, which is from the final evaluation dataset.
    #     This test is commented out beacuse the test data is too large to be commited to the repository.
    #     """
    #     log = init_test_log('Test_match_nearest_points/test_MT_OldBaldy_map')
    #     pred_seg_dir = 'tests/uncommited_data/pred_segmentations'
    #     true_seg_dir = 'tests/uncommited_data/true_segmentations'

    #     point_units = ['1_pt', '2_pt', '3_pt', '4_pt', '5_pt']
    #     for point_unit in point_units:
    #         self.run_test_match_nearest_points('MT_OldBaldyMountain_265833_1989_24000_geo_mosaic', point_unit, log, pred_seg_dir=pred_seg_dir, true_seg_dir=true_seg_dir)
    #     log.info('Test passed successfully')

class Test_match_by_color:
    def run_test_match_by_color(self, map_name, feature_name, log, color_range=4, map_dir=maps_dir, legend_dir=legends_dir):
        """
        Runs match_by_color for an arbitrary map and feature.
        Tests that the results generated by match_by_color are the same as the USGS grading metric. 
        match_by_color is used by detect_difficult_pixels function to generate the "easy pixels" for the polygon grading metric.
        This function is not a test itself.
        """
        map_image_filepath = os.path.join(map_dir, f'{map_name}.tif')
        legend_filepath = os.path.join(legend_dir, f'{map_name}.json')

        # Test our function
        map_image = io.loadGeoTiff(map_image_filepath)[0]
        legend = io.loadLegendJson(legend_filepath)
        feature = [f for f in legend.features if f.label == feature_name.split('_')[0]][0]
        test_result = grading.match_by_color(map_image, feature.bounding_box, color_range=color_range)

        # Get expected results from usgs grading
        usgs_result = usgs_grading.match_by_color(map_image.transpose(1,2,0), feature.bounding_box, color_range=color_range)

        ## Debug image of mask
        import matplotlib.pyplot as plt
        fig, ax = plt.subplots(1, 2)
        ax[0].imshow(test_result)
        ax[1].imshow(usgs_result)
        ax[0].set_title('Test Result')
        ax[1].set_title('USGS Result')
        plt.savefig(f'tests/logs/Test_match_by_color/{map_name}_{feature_name}_match_by_color.png')

        log.info(test_result.shape)
        log.info(usgs_result.shape)
        log.info(f'{map_name}_{feature_name} {test_result.shape[0]*test_result.shape[1] - sum(sum(test_result == usgs_result))} incorrect pixels')
        assert (test_result == usgs_result).all()

    def test_mock_map(self):
        """
        Tests that the results generated by match_by_color are the same as the USGS grading metric.
        Data used for this test is a mock map that is 100x100 pixels. The mock map has two poly features, L_poly and TZ_poly.
        """
        log = init_test_log('Test_match_by_color/test_mock_map')
        color_range = 4

        mock_poly_units = ['L_poly', 'TZ_poly']
        for poly_unit in mock_poly_units:
            self.run_test_match_by_color('mock_map', poly_unit, log, color_range=color_range)
        log.info('Test passed successfully')

class Test_detect_difficult_pixels:
    def run_test_detect_difficult_pixels(self, map_name, feature_name, log, color_range=4, set_false_as='hard', map_dir=maps_dir, legend_dir=legends_dir, true_seg_dir=true_segs_dir):
        """
        Runs detect_difficult_pixels for an arbitrary map and feature.
        Tests that the results generated by detect_difficult_pixels are the same as the USGS grading metric.
        detect_difficult_pixels is used by grade_poly_raster to generate the "easy pixels" for the polygon grading metric.
        This function is not a test itself.
        """
        map_image_filepath = os.path.join(map_dir, f'{map_name}.tif')
        legend_filepath = os.path.join(legend_dir, f'{map_name}.json')
        true_seg_filepath = os.path.join(true_seg_dir, f'{map_name}_{feature_name}.tif')

        # Test our function
        map_image = io.loadGeoTiff(map_image_filepath)[0]
        legend = io.loadLegendJson(legend_filepath)
        true_seg = np.squeeze(io.loadGeoTiff(true_seg_filepath)[0])
        feature = [f for f in legend.features if f.label == feature_name.split('_')[0]][0]
        test_result = grading.detect_difficult_pixels(map_image, true_seg, feature.bounding_box, color_range=color_range)

        # Get expected results from usgs grading
        usgs_result = usgs_grading.detect_difficult_pixels(map_image.transpose(1,2,0), true_seg, feature.bounding_box, color_range=color_range)

        ## Debug image of mask
        import matplotlib.pyplot as plt
        fig, ax = plt.subplots(1, 2)
        ax[0].imshow(test_result)
        ax[1].imshow(usgs_result)
        ax[0].set_title('Test Result')
        ax[1].set_title('USGS Result')
        plt.savefig(f'tests/logs/Test_detect_difficult_pixels/{map_name}_{feature_name}_detect_difficult_pixels.png')

        log.info(f'{map_name}_{feature_name} {test_result.shape[0]*test_result.shape[1] - sum(sum(test_result == usgs_result))} inccorect pixels')
        assert (test_result == usgs_result).all()
        assert (test_result.shape[0]*test_result.shape[1] - sum(sum(test_result == usgs_result))) == 0 # Number of inccorect values is 0
        
    def test_mock_map(self):
        """
        Tests that the results generated by detect_difficult_pixels are the same as the USGS grading metric.
        Data used for this test is a mock map that is 100x100 pixels. The mock map has two poly features, L_poly and TZ_poly.
        """
        log = init_test_log('Test_detect_difficult_pixels/test_mock_map')
        color_range = 4

        mock_poly_units = ['L_poly', 'TZ_poly']
        for poly_unit in mock_poly_units:
            self.run_test_detect_difficult_pixels('mock_map', poly_unit, log, color_range=color_range)
        log.info('Test passed successfully')
# endregion internal functions